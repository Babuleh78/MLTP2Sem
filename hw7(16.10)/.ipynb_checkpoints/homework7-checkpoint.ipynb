{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b64d4cd7-9c0b-47f2-bec8-80d85c1ea775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = 'cpu' # увы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4a5412-2fed-4177-8749-87af8cf4e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mat = scipy.io.loadmat('./devkit/cars_train_annos.mat')\n",
    "fname_to_class = {fname:cl-1 for fname, cl in zip([i[0] for i in mat['annotations'][0]['fname']], \n",
    "                                                [i[0][0] for i in mat['annotations'][0]['class']])}\n",
    "cars_meta = scipy.io.loadmat('./devkit/cars_meta.mat')\n",
    "id_to_car = {idx: car[0] for idx, car in enumerate(cars_meta['class_names'][0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2c92d3-8823-40de-9238-62fb4213fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_PATH = './cars_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e1829e-18e2-47cb-94be-9ec531171132",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.Resize(\n",
    "        size=(224, 224)\n",
    "    ),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class CropClassifDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, cars_items, transforms):\n",
    "        self.cars = cars_items\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename, cl_id = self.cars[idx]\n",
    "        image = cv2.imread(os.path.join(ADD_PATH, filename))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        sample = {'image': image, 'label': cl_id}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b79e178-8e3e-440a-9c59-4af578328a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(fname_to_class.items())\n",
    "random.shuffle(items)\n",
    "train_items = items[:int(len(items) * 0.8)]\n",
    "val_items = items[int(len(items) * 0.8):]\n",
    "\n",
    "train_dataset = CropClassifDataset(train_items, val_transforms)\n",
    "val_dataset = CropClassifDataset(val_items, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3264fd38-a7a5-4485-a771-153cc2bbacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, collate_fn=None, pin_memory=True, drop_last = True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, collate_fn=None, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d87680f-b0a6-47e8-ae9a-65f19b99ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.scheduler import TanhLRScheduler\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from timm.scheduler import TanhLRScheduler\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class CarClassifier(pl.LightningModule):\n",
    "    def __init__(self, class_dict, learning_rate, emb_size = 512):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.class_dict = class_dict\n",
    "        \n",
    "        self.model = resnet50()\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        \n",
    "        self.model.fc = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(in_features=2048, out_features=emb_size),\n",
    "                            torch.nn.ReLU(inplace=False),\n",
    "                            torch.nn.Linear(in_features=emb_size, out_features=len(class_dict)))\n",
    "                        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images = batch['image']\n",
    "        labels = batch['label'].to(torch.long)\n",
    "        preds = self.model(images)\n",
    "        loss = self.criterion(preds, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images = batch['image']\n",
    "        labels = batch['label'].to(torch.long)\n",
    "        preds = self.model(images)\n",
    "        loss = self.criterion(preds, labels)\n",
    "        self.log(\"validation_loss\", loss, sync_dist=True)\n",
    "        self.log(\"validation_accuracy\", torch.sum(torch.argmax(preds, dim = 1) == labels).item() / torch.tensor(labels.shape).item(), sync_dist=True)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        if len(images.shape) == 4:\n",
    "            preds = self.model(images) \n",
    "        else:\n",
    "            preds = self.model(images.unsqueeze(0))\n",
    "        preds = [self.class_dict[i.argmax().item()] for i in preds]\n",
    "        return preds\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return [optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb4feaa2-da1c-4925-8537-5de0ae65b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl_model = CarClassifier(id_to_car, 3e-4)\n",
    "checkpoint_callback = ModelCheckpoint(monitor='validation_accuracy', mode='max', save_top_k=3)\n",
    "# last_checkpoint = ModelCheckpoint(mode='max', monitor='time_log', save_top_k=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"validation_loss\", mode=\"min\", patience=2)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "# train model\n",
    "trainer = pl.Trainer(max_epochs=20, accelerator='cpu', devices = 1, strategy='auto', callbacks=[checkpoint_callback, early_stopping, lr_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f1150-6969-479a-9e4d-3fc684f12231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
